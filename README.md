______________
# CINEMATIC AI
<div align='center'>
    <img src='' height='300' title=''(image courtesy of Pexels) alt='Image of Project Topic with Description of Title'/>
</div>

![DALLÂ·E 2024-08-22 20 10 20 - A sleek, modern product image showcasing an AI model named 'Cinematic AI ' The design features a dark background with a cinematic feel, incorporating](https://github.com/user-attachments/assets/e32063c4-542d-4062-bc64-e59aa71d8943)
___________


## Project Team Members:
* Angel Alcantara
* Aniel Rios
* Antoine Baize
* Jeff Destine
* Josephine Robideau 
* Kalvin Anglin

## Table of Contents
* [Abstract](#Abstract)
* [Data](#Data)
* [Methods](#Methods)
* [Limitations](#Limitations)
* [Conclusions](#Conclusions)
* [References/Footnotes](#References/Footnotes)


## Abstract
Our movie recommendation system harnesses the power of sentiment analysis to deliver a personalized cinematic experience. By deeply analyzing movie reviews, we uncover the underlying emotional patterns that drive viewer preferences and behaviors. This also allows us to understand what recommendations truly resonate with each user based off the input they give us on the search bar.
Mapping these sentiments to film attributes allows users to match their current insights and explore new genres as our engine provides a seamless gateway to your next cinematic adventures. Our in-depth analysis empowers you to make well-informed viewing decisions in the future. 


**Project Overview:**
* Business Solution is applicable for the following industries:
    * Entertainment
    * Sales/Marketing
    * Healthcare
    * Education
    * Tech

* Text needed for Emotion Detection derived from the following data sources:
    * Chatbots/Virtual Assistants
    * Social Media
    * Reviews


 **Types of Sentiment Analysis**
* Fine Grained Sentiment Analysis: Polarity (positive, negative, neutral) and intensity of sentiment
* Aspect Based Sentiment Analysis: Specific aspects of product or service
* Emotion Detection: Emotion categories such as happy, sad, angry, etc.


## Purpose


## Goals & Problems Solved
-

## Process
### Data Collection and Cleanup
- 
### Cleanup
-
  -

### Exploration Process

### Recreate System
To achieve your objective,
	1. 
	2.
	3. 
	4.


### Tools Used
-

	
## Summary


## Problems Encountered
> -

## Data

We reviewed datasets that provided the most opportunity for a thorough exploration of our key questions:

* [Kaggle Emotions Dataset](https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp?resource=download)

* [Data World Sentiment Analysis Dataset](https://data.world/crowdflower/sentiment-analysis-in-text)

* [Data World Brands and Product Emotions](https://data.world/crowdflower/brands-and-product-emotions)

* [IMDB Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)

* [NYT Movie Reviews](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)

* [Yelp Reviews](https://www.kaggle.com/yelp-dataset/yelp-dataset)

* [Amazon Reviews](https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products)
---

## Project Management
|  Phases | Details|
| :--- | :--- |
| Data Fetching  | Google searches, Kaggle, Data World, IMDB, NYT    |
| Software Version Control | Repository created on GitHub, GitHub Projects used to create and track tasks based on key questions, Git branch used to upload files to from local computer to remote repository, utilized "compare & pull requests" to compare branch changes before merging into the main branch correlation, comparison, summary statistics, sentiment analysis, and time series analysis   |
| EDA | Imported CSV files, created dataframes, utlized pandas and python functions to search, select and handle missing data, identified keys features for further analysis    |
| Preprocessing  |  Utilized dictionarys, list, loops, column slicing, string manipulation, and train-test split to prevent data leakage and ensure high quality and structured data is visualized and fed into the models for text classification   |
| Model Selection & Tuning |  Utilized dictionarys, list, loops, column slicing, string manipulation, to ensure high quality and structured data is visualized and fed into the models for text classification   |

---
## Methods 

**Machine Learning Classification Models**
* Logistic Regression
* Random Forest
* Support Vector Machine

**Deep Learning Classification Models**

* VADER (Valence Aware Dictionary and Sentiment Reasoner) is a lexicon and rule-based sentiment analysis tool specifically designed for social media text. It uses a combination of sentiment lexicon and grammatical rules to analyze the sentiment of text data. VADER is known for its simplicity and effectiveness in analyzing sentiment in short texts like tweets, reviews, and comments. It provides a sentiment score ranging from -1 (negative) to 1 (positive) for each text input, along with scores for neutrality and compound sentiment. VADER is widely used for social media monitoring, customer feedback analysis, and sentiment analysis tasks where context and tone are important.

* BERT (Bidirectional Encoder Representations from Transformers) is a transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google. BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of NLP tasks. BERT has been widely adopted in academia and industry for various NLP tasks such as sentiment analysis, question answering, and named entity recognition.


* LSTM (Long Short-Term Memory) is a type of recurrent neural network (RNN) architecture that is well-suited for sequence prediction problems. LSTM networks are capable of learning long-term dependencies in sequential data and are widely used in natural language processing (NLP) tasks such as sentiment analysis, speech recognition, and machine translation. LSTM networks have a unique architecture that includes memory cells, input gates, output gates, and forget gates to control the flow of information through the network. This allows LSTM networks to capture long-range dependencies and model complex sequential patterns in the data.

**Learning Styles**
* Reinforcement Learning:
    * Supervised fine tuning
    * Human Preferences
    * Proximal Policy Optimization

* Developing Techniques:
    * One-shot learning
    * Zero-shot learning


**Platforms**
* [StreamLit](!https://streamlit.io/) 

* [Docker](https://hub.docker.com/r/jupyter/datascience-notebook/)

---
## Results

___
## Future Considerations


* **Lingering Questions**
    * **Datasets:** 

## Conclusion




## References/Footnotes
* https://www.motivationalinterviewing.org/sites/default/files/fogartyjco99.pdf
* https://www.tensorflow.org/text/tutorials/classify_text_with_bert
* https://www.kaggle.com/code/harshjain123/bert-for-everyone-tutorial-implementation
* https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6856204/#:~:text=We%20define%20neutral%20affect%20as,rather%20than%20a%20neutral%20reaction
* https://www.verywellmind.com/color-psychology-2795824
* https://www.kdnuggets.com/how-to-fine-tune-bert-sentiment-analysis-hugging-face-transformers
* https://kind.sigs.k8s.io/
